import os
import requests
from openai import OpenAI
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

class LlmClient:
        def __init__(self, model: str = None, apiKey: str = None, baseUrl: str = None, timeout: int = 30, stream: bool = False):
            self.model = model
            self.apiKey = apiKey
            self.baseUrl = baseUrl
            self.timeout = timeout
            self.stream = stream
            self.headers: dict[str, str] = {
                'Content-Type': 'application/json',
                'Authorization': f'Bearer {self.apiKey}'
            }
        def chat(self, messages: list[dict[str, str]], temperature: int = 0):
            data = {
                'model': self.model,
                'messages': messages,
                'temperature': temperature,
            }
            url = f'{self.baseUrl}/chat/completions'
            response = requests.post(url, json=data, headers=self.headers, timeout=self.timeout)
            print(f"ResponseType: {type(response)}")
            print(f"Response: {response}")
            print(f"ResponseJson: {response.json()}")

class OpenAiClient:
    def __init__(self, model: str = None, apiKey: str = None, baseUrl: str = None, timeout: int = 30):
        self.model = model
        self.client = OpenAI(api_key=apiKey, base_url=baseUrl, timeout=timeout)
    def chat(self, messages: list[dict[str, str]], temperature: int = 0, stream: bool = False):
        """
         è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæ€è€ƒï¼Œå¹¶è¿”å›å…¶å“åº”ã€‚
        """
        print(f"ğŸ§  æ­£åœ¨è°ƒç”¨ {self.model} æ¨¡å‹...")
        try:
            response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=temperature,
            stream=stream)
            print(f"ResponseType: {type(response)}")
            print(f"Response: {response}")
            print(f"ResponseJson: {response.model_dump_json()}")
        except Exception as e:
            print(f"âŒ è°ƒç”¨LLM APIæ—¶å‘ç”Ÿé”™è¯¯: {e}")


if __name__ == '__main__':
    model = os.getenv("LLM_MODEL_ID")
    apiKey = os.getenv("LLM_API_KEY")
    baseUrl = os.getenv("LLM_BASE_URL")
    messages = [
                {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"}
            ]
    openai_client = OpenAiClient(model=model, apiKey=apiKey, baseUrl=baseUrl)
    openai_client.chat(messages=messages)